Name:         v200-apache-atlas-6687ffb9d9-ntcm7
Namespace:    default
Priority:     0
Node:         cgk8s-node-1.fyre.ibm.com/9.20.193.94
Start Time:   Wed, 16 Jun 2021 09:43:27 +0100
Labels:       app.kubernetes.io/component=apache-atlas-service
              app.kubernetes.io/instance=v200
              app.kubernetes.io/name=ec-cts-apacheatlas
              pod-template-hash=6687ffb9d9
Annotations:  cni.projectcalico.org/podIP: 10.233.72.9/32
              cni.projectcalico.org/podIPs: 10.233.72.9/32
Status:       Running
IP:           10.233.72.9
IPs:
  IP:           10.233.72.9
Controlled By:  ReplicaSet/v200-apache-atlas-6687ffb9d9
Init Containers:
  init-connector:
    Container ID:  docker://2821b924f1da4e1cb89c4454e4302d2bcd94bcea2479cc68d09cdaa27ee50d0b
    Image:         docker.io/odpi/egeria-configure:2.10
    Image ID:      docker-pullable://odpi/egeria-configure@sha256:19168e2fe566b3908b7a7fe1a49288b598b1b4046793129c4a00b2cf4403c7f0
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      cd /opt/egeria/connectors && curl --location ${CONNECTOR_URL} --output ${CONNECTOR_JAR}
      
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 16 Jun 2021 09:43:29 +0100
      Finished:     Wed, 16 Jun 2021 09:43:31 +0100
    Ready:          True
    Restart Count:  0
    Environment Variables from:
      v200-configmap  ConfigMap  Optional: false
    Environment:      <none>
    Mounts:
      /opt/egeria/connectors from egeria-atlas-connector-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m8p54 (ro)
Containers:
  proxy:
    Container ID:   docker://f5ad8502de94d6015bb6111174a5995492944f3031f7bbda9d2915171e8b7b3b
    Image:          docker.io/odpi/egeria:2.10
    Image ID:       docker-pullable://odpi/egeria@sha256:4aa45a6b9b48c9cbab0eda265b9305013e092efd1f8f8700ef19258432413176
    Port:           9443/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Wed, 16 Jun 2021 09:43:32 +0100
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     1
      memory:  2Gi
    Requests:
      cpu:      250m
      memory:   1Gi
    Readiness:  tcp-socket :9443 delay=10s timeout=1s period=10s #success=1 #failure=6
    Environment Variables from:
      v200-configmap  ConfigMap  Optional: false
    Environment:
      LOADER_PATH:                                            /opt/egeria/connectors
      LOGGING_LEVEL_ORG_ODPI_EGERIA_CONNECTORS_APACHE_ATLAS:  DEBUG
    Mounts:
      /opt/egeria/connectors from egeria-atlas-connector-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m8p54 (ro)
  apache-atlas:
    Container ID:   docker://e2b730ffddfeb6232ee49e19e3d88af2776a8378ec6d9b6ab9de445a66ea1baf
    Image:          hyc-daell-infosvr-docker-local.artifactory.swg-devops.com/apache/atlas:v200-samples
    Image ID:       docker-pullable://hyc-daell-infosvr-docker-local.artifactory.swg-devops.com/apache/atlas@sha256:040a6af5781eee30189363591993a99ff1ff31758efa9656f303286883878415
    Ports:          21000/TCP, 9026/TCP, 9027/TCP
    Host Ports:     0/TCP, 0/TCP, 0/TCP
    State:          Running
      Started:      Wed, 16 Jun 2021 09:43:32 +0100
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     4
      memory:  4Gi
    Requests:
      cpu:        2
      memory:     2Gi
    Liveness:     http-get http://:21000/login.jsp delay=180s timeout=1s period=20s #success=1 #failure=3
    Readiness:    http-get http://:21000/login.jsp delay=180s timeout=1s period=20s #success=1 #failure=12
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m8p54 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  egeria-atlas-connector-volume:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  default-token-m8p54:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-m8p54
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  29m                default-scheduler  Successfully assigned default/v200-apache-atlas-6687ffb9d9-ntcm7 to cgk8s-node-1.fyre.ibm.com
  Normal   Pulled     29m                kubelet            Container image "docker.io/odpi/egeria-configure:2.10" already present on machine
  Normal   Created    29m                kubelet            Created container init-connector
  Normal   Started    29m                kubelet            Started container init-connector
  Normal   Pulled     29m                kubelet            Container image "docker.io/odpi/egeria:2.10" already present on machine
  Normal   Created    29m                kubelet            Created container proxy
  Normal   Started    29m                kubelet            Started container proxy
  Normal   Pulled     29m                kubelet            Container image "hyc-daell-infosvr-docker-local.artifactory.swg-devops.com/apache/atlas:v200-samples" already present on machine
  Normal   Created    29m                kubelet            Created container apache-atlas
  Normal   Started    29m                kubelet            Started container apache-atlas
  Warning  Unhealthy  29m (x3 over 29m)  kubelet            Readiness probe failed: dial tcp 10.233.72.9:9443: connect: connection refused
  Warning  Unhealthy  26m                kubelet            Readiness probe failed: Get "http://10.233.72.9:21000/login.jsp": context deadline exceeded (Client.Timeout exceeded while awaiting headers)

Name:         v200-init-and-report-7bffbbd9d8-fchq5
Namespace:    default
Priority:     0
Node:         cgk8s-node-3.fyre.ibm.com/9.20.194.199
Start Time:   Wed, 16 Jun 2021 09:43:27 +0100
Labels:       app.kubernetes.io/component=init-and-report
              app.kubernetes.io/instance=v200
              app.kubernetes.io/name=ec-cts-apacheatlas
              pod-template-hash=7bffbbd9d8
Annotations:  cni.projectcalico.org/podIP: 10.233.64.248/32
              cni.projectcalico.org/podIPs: 10.233.64.248/32
Status:       Running
IP:           10.233.64.248
IPs:
  IP:           10.233.64.248
Controlled By:  ReplicaSet/v200-init-and-report-7bffbbd9d8
Init Containers:
  wait-for-atlasproxy:
    Container ID:   docker://6e0f991258ee360997caffd977a44c83963ac97af617fb676850e6274878dfb5
    Image:          docker.io/odpi/egeria-configure:2.10
    Image ID:       docker-pullable://odpi/egeria-configure@sha256:19168e2fe566b3908b7a7fe1a49288b598b1b4046793129c4a00b2cf4403c7f0
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 16 Jun 2021 09:43:29 +0100
      Finished:     Wed, 16 Jun 2021 09:46:56 +0100
    Ready:          True
    Restart Count:  0
    Environment:
      SERVICE:  v200-apache-atlas-service
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from v200-cts-token-fmfjj (ro)
  wait-for-kafka:
    Container ID:   docker://882ca4bddc82da3c551a063be9c5d73788f8bb81d77540fb4ecaa7696871efc4
    Image:          docker.io/odpi/egeria-configure:2.10
    Image ID:       docker-pullable://odpi/egeria-configure@sha256:19168e2fe566b3908b7a7fe1a49288b598b1b4046793129c4a00b2cf4403c7f0
    Port:           <none>
    Host Port:      <none>
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 16 Jun 2021 09:46:57 +0100
      Finished:     Wed, 16 Jun 2021 09:46:57 +0100
    Ready:          True
    Restart Count:  0
    Environment:
      SERVICE:  v200-kafka
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from v200-cts-token-fmfjj (ro)
  wait-for-apache-atlas:
    Container ID:  docker://cf00c52b19d3d4b9656da2a42273cf7f747a26ce2eeda47179a3fe4b68e10f8a
    Image:         docker.io/odpi/egeria-configure:2.10
    Image ID:      docker-pullable://odpi/egeria-configure@sha256:19168e2fe566b3908b7a7fe1a49288b598b1b4046793129c4a00b2cf4403c7f0
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      until $(curl -s -f --connect-timeout 5 --url http://v200-apache-atlas-service:${ATLAS_PORT}/login.jsp &>/dev/null); do echo waiting for http://v200-apache-atlas-service:${ATLAS_PORT}/login.jsp to be accessible; sleep 2; done;
      
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 16 Jun 2021 09:46:58 +0100
      Finished:     Wed, 16 Jun 2021 09:46:58 +0100
    Ready:          True
    Restart Count:  0
    Environment Variables from:
      v200-configmap  ConfigMap  Optional: false
    Environment:      <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from v200-cts-token-fmfjj (ro)
Containers:
  init-and-report:
    Container ID:  docker://388ef599dca47e58e09ad5e92ddfc0237c74048f07b8f4b000aae4bfbf2f29d5
    Image:         docker.io/odpi/egeria-configure:2.10
    Image ID:      docker-pullable://odpi/egeria-configure@sha256:19168e2fe566b3908b7a7fe1a49288b598b1b4046793129c4a00b2cf4403c7f0
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/bash
      -c
      curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/server-url-root?url=${ATLAS_ENDPOINT} && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/server-type?typeName=Conformance && curl -k -f --verbose --basic admin:admin -X POST --header "Content-Type: application/json" ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/event-bus?topicURLRoot=egeria --data '{"producer": {"bootstrap.servers": "'"${KAFKA_ENDPOINT}"'"}, "consumer": {"bootstrap.servers": "'"${KAFKA_ENDPOINT}"'"} }' && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/cohorts/${EGERIA_COHORT} && curl -k -f --verbose --basic admin:admin -X POST --header "Content-Type: application/json" ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/conformance-suite-workbenches/repository-workbench/repositories --data '{"class":"RepositoryConformanceWorkbenchConfig","tutRepositoryServerName":"'"${ATLAS_SERVER}"'","maxSearchResults":5}' && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/instance && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/server-type?typeName=Apache%20Atlas && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/organization-name?name=ODPi && curl -k -f --verbose --basic admin:admin -X POST --header "Content-Type: application/json" ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/event-bus?topicURLRoot=egeria --data '{"producer": {"bootstrap.servers": "'"${KAFKA_ENDPOINT}"'"}, "consumer": {"bootstrap.servers": "'"${KAFKA_ENDPOINT}"'"} }' && curl -k -f --verbose --basic admin:admin -X POST --header "Content-Type: application/json" ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/local-repository/mode/repository-proxy/connection --data '{"class":"Connection","connectorType":{"class":"ConnectorType","connectorProviderClassName":"org.odpi.egeria.connectors.apache.atlas.repositoryconnector.ApacheAtlasOMRSRepositoryConnectorProvider"},"endpoint":{"class":"Endpoint","address":"'"${ATLAS_HOST}:${ATLAS_PORT}"'","protocol":"http"},"userId":"'"${ATLAS_USER}"'","clearPassword":"'"${ATLAS_PASS}"'","configurationProperties":{"defaultZones":["default"]}}' && curl -k -f --verbose --basic admin:admin -X POST ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/cohorts/${EGERIA_COHORT} && curl -k -f --verbose --basic admin:admin -X POST "${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/local-repository/event-mapper-details?connectorProvider=org.odpi.egeria.connectors.apache.atlas.eventmapper.ApacheAtlasOMRSRepositoryEventMapperProvider&eventSource=${ATLAS_KAFKA_ENDPOINT}" && curl -k -f --verbose --basic admin:admin -X POST --max-time 900 ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/instance && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/cts/configuration > /tmp/omag.server.cts.config && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/open-metadata/admin-services/users/${EGERIA_USER}/servers/${ATLAS_SERVER}/configuration > /tmp/omag.server.${ATLAS_SERVER}.config && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/servers/cts/open-metadata/repository-services/users/${EGERIA_USER}/metadata-highway/local-registration > /tmp/cohort.${EGERIA_COHORT}.cts.local && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/servers/cts/open-metadata/repository-services/users/${EGERIA_USER}/metadata-highway/cohorts/${EGERIA_COHORT}/remote-members > /tmp/cohort.${EGERIA_COHORT}.cts.remote && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/servers/${ATLAS_SERVER}/open-metadata/repository-services/users/${EGERIA_USER}/metadata-highway/local-registration > /tmp/cohort.${EGERIA_COHORT}.${ATLAS_SERVER}.local && curl -k -f --verbose --basic admin:admin -X GET ${ATLAS_ENDPOINT}/servers/${ATLAS_SERVER}/open-metadata/repository-services/users/${EGERIA_USER}/metadata-highway/cohorts/${EGERIA_COHORT}/remote-members > /tmp/cohort.${EGERIA_COHORT}.${ATLAS_SERVER}.remote && echo ""; echo "Waiting 2 minutes for CTS to start..."; sleep 120 && until [ $(curl -k -f --silent --basic admin:admin -X GET ${ATLAS_ENDPOINT}/servers/cts/open-metadata/conformance-suite/users/${EGERIA_USER}/status/workbenches/repository-workbench | jq '.workbenchStatus.workbenchComplete') == "true" ]; do echo "... waiting for CTS to complete"; sleep 20; done && curl -k -f --silent --basic admin:admin -X GET --max-time 900 ${ATLAS_ENDPOINT}/servers/cts/open-metadata/conformance-suite/users/${EGERIA_USER}/report > /tmp/openmetadata.conformance.testlab.results && cd /tmp; tar cvf ${CTS_REPORT_NAME}.tar *.config cohort.* openmetadata.conformance.testlab.results; gzip ${CTS_REPORT_NAME}.tar && echo "Complete -- CTS results available to download from /tmp/${CTS_REPORT_NAME}.tar.gz" && tail -f /dev/null
      
    State:          Running
      Started:      Wed, 16 Jun 2021 09:46:59 +0100
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     500m
      memory:  64Mi
    Requests:
      cpu:     100m
      memory:  16Mi
    Environment Variables from:
      v200-configmap  ConfigMap  Optional: false
    Environment:      <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from v200-cts-token-fmfjj (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  v200-cts-token-fmfjj:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  v200-cts-token-fmfjj
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  29m   default-scheduler  Successfully assigned default/v200-init-and-report-7bffbbd9d8-fchq5 to cgk8s-node-3.fyre.ibm.com
  Normal  Pulled     29m   kubelet            Container image "docker.io/odpi/egeria-configure:2.10" already present on machine
  Normal  Created    29m   kubelet            Created container wait-for-atlasproxy
  Normal  Started    29m   kubelet            Started container wait-for-atlasproxy
  Normal  Pulled     26m   kubelet            Container image "docker.io/odpi/egeria-configure:2.10" already present on machine
  Normal  Started    26m   kubelet            Started container wait-for-kafka
  Normal  Created    26m   kubelet            Created container wait-for-kafka
  Normal  Pulled     26m   kubelet            Container image "docker.io/odpi/egeria-configure:2.10" already present on machine
  Normal  Created    26m   kubelet            Created container wait-for-apache-atlas
  Normal  Started    26m   kubelet            Started container wait-for-apache-atlas
  Normal  Pulled     26m   kubelet            Container image "docker.io/odpi/egeria-configure:2.10" already present on machine
  Normal  Created    26m   kubelet            Created container init-and-report
  Normal  Started    26m   kubelet            Started container init-and-report

Name:         v200-kafka-0
Namespace:    default
Priority:     0
Node:         cgk8s-node-3.fyre.ibm.com/9.20.194.199
Start Time:   Wed, 16 Jun 2021 09:43:27 +0100
Labels:       app.kubernetes.io/component=kafka
              app.kubernetes.io/instance=v200
              app.kubernetes.io/managed-by=Helm
              app.kubernetes.io/name=kafka
              controller-revision-hash=v200-kafka-f76c9d6db
              helm.sh/chart=kafka-7.0.4
              statefulset.kubernetes.io/pod-name=v200-kafka-0
Annotations:  cni.projectcalico.org/podIP: 10.233.64.249/32
              cni.projectcalico.org/podIPs: 10.233.64.249/32
Status:       Running
IP:           10.233.64.249
IPs:
  IP:           10.233.64.249
Controlled By:  StatefulSet/v200-kafka
Containers:
  kafka:
    Container ID:   docker://a697262cdd7685ca8bc15c55bd6d4f4ad4147a14f6185c6a94be47ec14037197
    Image:          docker.io/bitnami/kafka:2.3.1-debian-9-r21
    Image ID:       docker-pullable://bitnami/kafka@sha256:c8f86b2bba447bec12dbda8c6ec48bada65f59ca67cd5dba04e41cf5373f2162
    Port:           9092/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Wed, 16 Jun 2021 09:43:30 +0100
    Ready:          True
    Restart Count:  0
    Liveness:       tcp-socket :kafka delay=10s timeout=5s period=10s #success=1 #failure=2
    Readiness:      tcp-socket :kafka delay=5s timeout=5s period=10s #success=1 #failure=6
    Environment:
      BITNAMI_DEBUG:                                       false
      MY_POD_IP:                                            (v1:status.podIP)
      MY_POD_NAME:                                         v200-kafka-0 (v1:metadata.name)
      KAFKA_CFG_ZOOKEEPER_CONNECT:                         v200-zookeeper
      KAFKA_PORT_NUMBER:                                   9092
      KAFKA_CFG_LISTENERS:                                 PLAINTEXT://:$(KAFKA_PORT_NUMBER)
      KAFKA_CFG_ADVERTISED_LISTENERS:                      PLAINTEXT://$(MY_POD_NAME).v200-kafka-headless.default.svc.cluster.local:$(KAFKA_PORT_NUMBER)
      ALLOW_PLAINTEXT_LISTENER:                            yes
      KAFKA_CFG_BROKER_ID:                                 -1
      KAFKA_CFG_DELETE_TOPIC_ENABLE:                       false
      KAFKA_HEAP_OPTS:                                     -Xmx1024m -Xms1024m
      KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES:               10000
      KAFKA_CFG_LOG_FLUSH_INTERVAL_MS:                     1000
      KAFKA_CFG_LOG_RETENTION_BYTES:                       1073741824
      KAFKA_CFG_LOG_RETENTION_CHECK_INTERVALS_MS:          300000
      KAFKA_CFG_LOG_RETENTION_HOURS:                       168
      KAFKA_CFG_MESSAGE_MAX_BYTES:                         1000012
      KAFKA_CFG_LOG_SEGMENT_BYTES:                         1073741824
      KAFKA_CFG_LOG_DIRS:                                  /bitnami/kafka/data
      KAFKA_CFG_DEFAULT_REPLICATION_FACTOR:                1
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR:          1
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:  1
      KAFKA_CFG_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM:     https
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR:             1
      KAFKA_CFG_NUM_IO_THREADS:                            8
      KAFKA_CFG_NUM_NETWORK_THREADS:                       3
      KAFKA_CFG_NUM_PARTITIONS:                            1
      KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR:         1
      KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES:               102400
      KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES:                  104857600
      KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES:                  102400
      KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS:           6000
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m8p54 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  default-token-m8p54:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-m8p54
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  29m   default-scheduler  Successfully assigned default/v200-kafka-0 to cgk8s-node-3.fyre.ibm.com
  Normal  Pulled     29m   kubelet            Container image "docker.io/bitnami/kafka:2.3.1-debian-9-r21" already present on machine
  Normal  Created    29m   kubelet            Created container kafka
  Normal  Started    29m   kubelet            Started container kafka

Name:         v200-zookeeper-0
Namespace:    default
Priority:     0
Node:         cgk8s-node-3.fyre.ibm.com/9.20.194.199
Start Time:   Wed, 16 Jun 2021 09:43:27 +0100
Labels:       app.kubernetes.io/component=zookeeper
              app.kubernetes.io/instance=v200
              app.kubernetes.io/name=zookeeper
              controller-revision-hash=v200-zookeeper-66bfd689
              helm.sh/chart=zookeeper-5.1.1
              statefulset.kubernetes.io/pod-name=v200-zookeeper-0
Annotations:  cni.projectcalico.org/podIP: 10.233.64.250/32
              cni.projectcalico.org/podIPs: 10.233.64.250/32
Status:       Running
IP:           10.233.64.250
IPs:
  IP:           10.233.64.250
Controlled By:  StatefulSet/v200-zookeeper
Containers:
  zookeeper:
    Container ID:  docker://65c1ba005bb660b6d7e239ad81e688b9f39a327455e555e5d7a7d34a2a7dd515
    Image:         docker.io/bitnami/zookeeper:3.5.6-debian-9-r20
    Image ID:      docker-pullable://bitnami/zookeeper@sha256:0c546cc26e4d3a53a8f4f58e0517e1903c862a60ff03d9b5e9f5beb6acca8683
    Ports:         2181/TCP, 2888/TCP, 3888/TCP
    Host Ports:    0/TCP, 0/TCP, 0/TCP
    Command:
      bash
      -ec
      # Execute entrypoint as usual after obtaining ZOO_SERVER_ID based on POD hostname
      HOSTNAME=`hostname -s`
      if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
        ORD=${BASH_REMATCH[2]}
        export ZOO_SERVER_ID=$((ORD+1))
      else
        echo "Failed to get index from hostname $HOST"
        exit 1
      fi
      exec /entrypoint.sh /run.sh
      
    State:          Running
      Started:      Wed, 16 Jun 2021 09:43:30 +0100
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:      250m
      memory:   256Mi
    Liveness:   tcp-socket :client delay=30s timeout=5s period=10s #success=1 #failure=6
    Readiness:  tcp-socket :client delay=5s timeout=5s period=10s #success=1 #failure=6
    Environment:
      ZOO_PORT_NUMBER:             2181
      ZOO_TICK_TIME:               2000
      ZOO_INIT_LIMIT:              10
      ZOO_SYNC_LIMIT:              5
      ZOO_MAX_CLIENT_CNXNS:        60
      ZOO_4LW_COMMANDS_WHITELIST:  srvr, mntr
      ZOO_SERVERS:                 v200-zookeeper-0.v200-zookeeper-headless.default.svc.cluster.local:2888:3888
      ZOO_ENABLE_AUTH:             no
      ZOO_HEAP_SIZE:               1024
      ZOO_LOG_LEVEL:               ERROR
      ALLOW_ANONYMOUS_LOGIN:       yes
    Mounts:
      /bitnami/zookeeper from data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m8p54 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  default-token-m8p54:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-m8p54
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  29m   default-scheduler  Successfully assigned default/v200-zookeeper-0 to cgk8s-node-3.fyre.ibm.com
  Normal  Pulled     29m   kubelet            Container image "docker.io/bitnami/zookeeper:3.5.6-debian-9-r20" already present on machine
  Normal  Created    29m   kubelet            Created container zookeeper
  Normal  Started    29m   kubelet            Started container zookeeper

